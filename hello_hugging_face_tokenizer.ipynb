{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Hugging Face Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre-trained model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8645,   876,  9552,   481,   287,   262,  2003,  2148, 11781,  5479,\n",
      "           329,   262,  2214,   286]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Make up some text\n",
    "my_text = \"Generative AI will in the future provide promising applications for the field of\"\n",
    "tokens = tokenizer(my_text, return_tensors=\"pt\")\n",
    "\n",
    "# Display tokens\n",
    "print(tokens[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look into the Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(8645)</td>\n",
       "      <td>Gener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(876)</td>\n",
       "      <td>ative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(9552)</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(481)</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(287)</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(262)</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(2003)</td>\n",
       "      <td>future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(2148)</td>\n",
       "      <td>provide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(11781)</td>\n",
       "      <td>promising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(5479)</td>\n",
       "      <td>applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tensor(329)</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tensor(262)</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tensor(2214)</td>\n",
       "      <td>field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tensor(286)</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id          token\n",
       "0    tensor(8645)          Gener\n",
       "1     tensor(876)          ative\n",
       "2    tensor(9552)             AI\n",
       "3     tensor(481)           will\n",
       "4     tensor(287)             in\n",
       "5     tensor(262)            the\n",
       "6    tensor(2003)         future\n",
       "7    tensor(2148)        provide\n",
       "8   tensor(11781)      promising\n",
       "9    tensor(5479)   applications\n",
       "10    tensor(329)            for\n",
       "11    tensor(262)            the\n",
       "12   tensor(2214)          field\n",
       "13    tensor(286)             of"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def display_tokens(tokens, tokenizer):\n",
    "    return pd.DataFrame([(id, tokenizer.decode(id)) for id in tokens[\"input_ids\"][0]], columns=[\"id\",\"token\"])\n",
    "\n",
    "display_tokens(tokens, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the next token probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11666</th>\n",
       "      <td>11666</td>\n",
       "      <td>artificial</td>\n",
       "      <td>0.237438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>9552</td>\n",
       "      <td>AI</td>\n",
       "      <td>0.081239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35941</th>\n",
       "      <td>35941</td>\n",
       "      <td>Artificial</td>\n",
       "      <td>0.066997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36359</th>\n",
       "      <td>36359</td>\n",
       "      <td>robotics</td>\n",
       "      <td>0.038756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>4572</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.026404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>3644</td>\n",
       "      <td>computer</td>\n",
       "      <td>0.019377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31350</th>\n",
       "      <td>31350</td>\n",
       "      <td>computational</td>\n",
       "      <td>0.015083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>10870</td>\n",
       "      <td>cognitive</td>\n",
       "      <td>0.013064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>12661</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>0.012315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17019</th>\n",
       "      <td>17019</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.012304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           token  probability\n",
       "11666  11666      artificial     0.237438\n",
       "9552    9552              AI     0.081239\n",
       "35941  35941      Artificial     0.066997\n",
       "36359  36359        robotics     0.038756\n",
       "4572    4572         machine     0.026404\n",
       "3644    3644        computer     0.019377\n",
       "31350  31350   computational     0.015083\n",
       "10870  10870       cognitive     0.013064\n",
       "12661  12661     intelligent     0.012315\n",
       "17019  17019          neural     0.012304"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the probabilities for likely next token and display top 10\n",
    "with torch.no_grad():\n",
    "    logits = model(**tokens).logits[:, -1, :]\n",
    "    probabilities = torch.nn.functional.softmax(logits[0], dim=-1)\n",
    "\n",
    "\n",
    "def display_likely_next_tokens(probabilities, tokenizer, top_n=5):\n",
    "    return pd.DataFrame(\n",
    "        [(id, tokenizer.decode(id), p.item()) for id, p in enumerate(probabilities) if p.item() ],\n",
    "        columns=[\"id\", \"token\", \"probability\"],\n",
    "    ).sort_values(\"probability\", ascending=False)[:top_n]\n",
    "\n",
    "\n",
    "display_likely_next_tokens(probabilities, tokenizer, top_n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely next token_id: 11666\n",
      "Most likely next token:  artificial\n"
     ]
    }
   ],
   "source": [
    "# Get the next token\n",
    "next_token_id = torch.argmax(probabilities).item()\n",
    "\n",
    "print(f\"Most likely next token_id: {next_token_id}\")\n",
    "print(f\"Most likely next token: {tokenizer.decode(next_token_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI will in the future provide promising applications for the field of artificial\n"
     ]
    }
   ],
   "source": [
    "# Append to the original sentence\n",
    "my_text = my_text + tokenizer.decode(11666)\n",
    "print(my_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate more text with generate() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In the beginning, machine learning was a very simple concept. It was a way to learn about the world. It was a way to learn about the world. It was a way to learn about the world. It was a way to learn about the world. It was a way to learn about the world. It was"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Tokenize some random text\n",
    "my_text_2 = \"In the beginning, machine learning was\"\n",
    "tokens = tokenizer(my_text_2, return_tensors=\"pt\")\n",
    "\n",
    "# generate more text \n",
    "output = model.generate(**tokens, max_length=64, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Display markdown\n",
    "display(Markdown(tokenizer.decode(output[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
