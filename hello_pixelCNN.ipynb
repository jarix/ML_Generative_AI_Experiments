{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e376eee8",
   "metadata": {},
   "source": [
    "# Hello PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39901b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:  3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, callbacks\n",
    "\n",
    "from utils import display\n",
    "\n",
    "print(\"Python Version: \", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3df02",
   "metadata": {},
   "source": [
    "### Get Data\n",
    "Use FashionMNIST from TensorFlow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9554f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, _), (_, _) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ea277",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a5c88",
   "metadata": {},
   "source": [
    "Scale down in size and image depth to make the training time reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9ee1fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_SIZE = 16\n",
    "PIXEL_LEVELS = 4\n",
    "\n",
    "# Function to preprocess the images\n",
    "def preprocess(imgs_int):\n",
    "    imgs_int = np.expand_dims(imgs_int, -1)\n",
    "    imgs_int = tf.image.resize(imgs_int, (IMAGE_SIZE, IMAGE_SIZE)).numpy()\n",
    "    imgs_int = (imgs_int / (256 / PIXEL_LEVELS)).astype(int)\n",
    "    imgs = imgs_int.astype(\"float32\")\n",
    "    imgs = imgs / PIXEL_LEVELS\n",
    "    return imgs, imgs_int\n",
    "\n",
    "\n",
    "# Preprocess the training data\n",
    "input_data, output_data = preprocess(x_train)\n",
    "\n",
    "# Display some sample preprocessed images\n",
    "display(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce34e74",
   "metadata": {},
   "source": [
    "### Define PixelCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ddd45e",
   "metadata": {},
   "source": [
    "#### Define Masked Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d857c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type A: value of the central pixel is masked\n",
    "# Type B: value of the central pixel is not masked\n",
    "class MaskedConv2D(layers.Layer):\n",
    "    def __init__(self, mask_type, **kwargs):\n",
    "        super(MaskedConv2D, self).__init__()\n",
    "        self.mask_type = mask_type\n",
    "        self.conv = layers.Conv2D(**kwargs)    # Based on regular Conv2D layer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Build the conv2d layer to initialize kernel variables\n",
    "        self.conv.build(input_shape)\n",
    "        # Use the initialized kernel to create the mask\n",
    "        kernel_shape = self.conv.kernel.shape\n",
    "        self.mask = np.zeros(shape=kernel_shape)   # Intialize mask with zeros\n",
    "        self.mask[: kernel_shape[0] // 2, ...] = 1.0  # preceding rows set to 1.0\n",
    "        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
    "        if self.mask_type == \"B\": # Type B: central pixel is not masked\n",
    "            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.conv.kernel.assign(self.conv.kernel * self.mask)  # Multiply the mask with filter weights\n",
    "        return self.conv(inputs)\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6ac4c",
   "metadata": {},
   "source": [
    "#### Define Residual Blocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2ee767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.conv1 = layers.Conv2D(\n",
    "            filters=filters // 2, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "        self.pixel_conv = MaskedConv2D(\n",
    "            mask_type=\"B\",\n",
    "            filters=filters // 2,\n",
    "            kernel_size=3,\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.conv2 = layers.Conv2D(\n",
    "            filters=filters, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pixel_conv(x)\n",
    "        x = self.conv2(x)\n",
    "        return layers.add([inputs, x])\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ea784",
   "metadata": {},
   "source": [
    "#### Define PixelCNN itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d01046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedConv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,504</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,504</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,504</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,504</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedConv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedConv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_conv2d_2 (\u001b[38;5;33mMaskedConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m6,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block (\u001b[38;5;33mResidualBlock\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m53,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m53,504\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m53,504\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m53,504\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ residual_block_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m53,504\u001b[0m │\n",
       "│ (\u001b[38;5;33mResidualBlock\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_conv2d_8 (\u001b[38;5;33mMaskedConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_conv2d_9 (\u001b[38;5;33mMaskedConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,460</span> (1.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m307,460\u001b[0m (1.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,460</span> (1.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m307,460\u001b[0m (1.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FILTERS = 128    # Number of filters in the convolutional layers\n",
    "RESIDUAL_BLOCKS = 5   # Number of residual blocks in the network\n",
    "\n",
    "# Define the PixelCNN model\n",
    "inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "x = MaskedConv2D(\n",
    "    mask_type=\"A\",\n",
    "    filters=N_FILTERS,\n",
    "    kernel_size=7,\n",
    "    activation=\"relu\",\n",
    "    padding=\"same\",\n",
    ")(inputs)\n",
    "\n",
    "for _ in range(RESIDUAL_BLOCKS):\n",
    "    x = ResidualBlock(filters=N_FILTERS)(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    x = MaskedConv2D(\n",
    "        mask_type=\"B\",\n",
    "        filters=N_FILTERS,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        activation=\"relu\",\n",
    "        padding=\"valid\",\n",
    "    )(x)\n",
    "\n",
    "out = layers.Conv2D(\n",
    "    filters=PIXEL_LEVELS,\n",
    "    kernel_size=1,\n",
    "    strides=1,\n",
    "    activation=\"softmax\",\n",
    "    padding=\"valid\",\n",
    ")(x)\n",
    "\n",
    "pixel_cnn = models.Model(inputs, out)\n",
    "pixel_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1831ce",
   "metadata": {},
   "source": [
    "### Train the PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de31eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(learning_rate=0.0005)\n",
    "pixel_cnn.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daa0fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img):\n",
    "        self.num_img = num_img\n",
    "\n",
    "    def sample_from(self, probs, temperature):  # <2>\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "        return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "    def generate(self, temperature):\n",
    "        generated_images = np.zeros(\n",
    "            shape=(self.num_img,) + (pixel_cnn.input_shape)[1:]\n",
    "        )\n",
    "        batch, rows, cols, channels = generated_images.shape\n",
    "\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                for channel in range(channels):\n",
    "                    probs = self.model.predict(generated_images, verbose=0)[\n",
    "                        :, row, col, :\n",
    "                    ]\n",
    "                    generated_images[:, row, col, channel] = [\n",
    "                        self.sample_from(x, temperature) for x in probs\n",
    "                    ]\n",
    "                    generated_images[:, row, col, channel] /= PIXEL_LEVELS\n",
    "\n",
    "        return generated_images\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_images = self.generate(temperature=1.0)\n",
    "        display(\n",
    "            generated_images,\n",
    "            save_to=\"./output/generated_img_%03d.png\" % (epoch),\n",
    "        )\n",
    "\n",
    "\n",
    "img_generator_callback = ImageGenerator(num_img=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be9de373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.6387"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output/generated_img_000.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the PixelCNN model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mpixel_cnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_generator_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[16], line 33\u001b[0m, in \u001b[0;36mImageGenerator.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m     generated_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerated_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./output/generated_img_\u001b[39;49m\u001b[38;5;132;43;01m%03d\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\utils.py:29\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(images, n, size, cmap, as_type, save_to)\u001b[0m\n\u001b[0;32m     26\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_to:\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_to\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSaved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_to\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:1243\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1240\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[1;32m-> 1243\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\matplotlib\\figure.py:3490\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3488\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3489\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[1;32m-> 3490\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\matplotlib\\backend_bases.py:2184\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2184\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2185\u001b[0m             filename,\n\u001b[0;32m   2186\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2187\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2188\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2189\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2190\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\matplotlib\\backend_bases.py:2040\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2036\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2037\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2038\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2039\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2040\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:481\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:430\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    429\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 430\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\matplotlib\\image.py:1634\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1632\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1633\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1634\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGithub\\ML_Generative_AI_Experiments\\.venv\\Lib\\site-packages\\PIL\\Image.py:2591\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2589\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2591\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2593\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/generated_img_000.png'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150\n",
    "\n",
    "# Train the PixelCNN model\n",
    "pixel_cnn.fit(\n",
    "    input_data,\n",
    "    output_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[tensorboard_callback, img_generator_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc8cca",
   "metadata": {},
   "source": [
    "### Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf37a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = img_generator_callback.generate(temperature=1.0)\n",
    "display(generated_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
